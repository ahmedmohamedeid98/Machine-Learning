{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model by using ''pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225108225108225\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "# prepare data \n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "label = df['Outcome'].values\n",
    "features = df[list(columns)].values\n",
    "\n",
    "# split data to training part and testing part\n",
    "X_train, X_test , y_train, y_test = train_test_split(features, label, test_size = 0.30)\n",
    "\n",
    "## prepare Model type\n",
    "#clf = RandomForestClassifier(n_estimators=1)\n",
    "\n",
    "## fitting data\n",
    "#clf = clf.fit(X_train , y_train)\n",
    "## saving the model\n",
    "#with open(\"randomforestclassifier.pickle\",'wb') as f:\n",
    "#    pickle.dump(clf , f)\n",
    "\n",
    "# every time load saved model \n",
    "model_file = open('randomforestclassifier.pickle' , 'rb')\n",
    "clf = pickle.load(model_file)\n",
    "\n",
    "# testing accuracy\n",
    "accuracy = clf.score(X_test , y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why we need to save the model ?\n",
    "if we have data with size 4 GB\n",
    "if we trained the model every time that is hard for the cpu and will take alot of time so we training the model just first \n",
    "time and then save it for use it later.\n",
    "\n",
    "if we have data with size 500 TB\n",
    "it impossible to train this model in our pc or labtop so, we will train it on remote server just first time and save it for use it in our prorams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "example = np.array([[12,150,50,40,500,32,1.56,70],[12,0,22,40,100,32,1.56,60]])\n",
    "example = example.reshape(len(example),-1)\n",
    "\n",
    "p = clf.predict(example)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
